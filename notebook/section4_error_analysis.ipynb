{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4721f7d-9c44-48ca-893f-dbe90fa6ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "HERE = %pwd\n",
    "sys.path.append(os.path.dirname(HERE))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec104f9-0a8b-4c4c-ac9c-6ea026e2317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "from src import utils, main, post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acaad41-09e0-40a8-b14f-b9e6a1f79711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed directory\n",
    "version_infer = \"20250404_infer\"\n",
    "version_input = \"20250403_input\"\n",
    "version_prep = \"20250403_prep\"\n",
    "n_user = 200  \n",
    "n_user_exp = 100\n",
    "\n",
    "# LLM names\n",
    "d_model = {\n",
    "    \"gpt-4.1-mini-2025-04-14\" : \"gpt-4.1-mini\",\n",
    "    \"llama3-3-70b-instruct-v1\" : \"llama3.3-70b\", \n",
    "    \"gpt-4o-mini-2024-07-18\" : \"gpt-4o-mini\", \n",
    "    \"phi4\" : \"phi4\",\n",
    "    \"nova-lite-v1\" : \"amazon-nova-lite\"\n",
    "}\n",
    "model_names = list(d_model.keys())\n",
    "model_names_short = list(d_model.values())\n",
    "\n",
    "# data names\n",
    "data_names = [\"Yelp\", \"MIND\", \"Food\"] + [f\"Amazon_{a}\" for a in [\"Movie\", \"Music\", \"Grocery\", \"Clothes\", \"Book\"]]\n",
    "\n",
    "# prompt names\n",
    "# comments are renamed prompt names for submitted paper\n",
    "types_prompt = [\n",
    "    f\"ItemAll_Method{b}\" \n",
    "    for b in [\n",
    "        \"Baseline\", \n",
    "        \"Emotion\", \n",
    "        \"Re-Reading\",\n",
    "        \"Bothinst\",  # Both-Inst\n",
    "        \"RecencyFocused\",  # Recency-Focused\n",
    "        \"Pretend\",  # RolePlay-User\n",
    "        \"Baseline_SystemRole\",  # RolePlay-Expert\n",
    "        \"Baseline_Naming\",  # RolePlay-Frederick\n",
    "        \"Baseline_ItemSummary\",  # Summarize-Item\n",
    "        \"StepBack\",  # Step-Back\n",
    "        \"ReAct\",\n",
    "        \"Rephrase\",\n",
    "        \"Echo\",\n",
    "        \"UserSummarization\",  # Summarize-User\n",
    "        \"ItemGenerate\",  # Generate-Item\n",
    "        \"ItemGenerateTrue\",  # Reuse-Item\n",
    "        \"Explain\",\n",
    "        \"Mock\",                \n",
    "        \"ZSCoT\",  # Step-by-Step\n",
    "        \"TakeBreath\",  # Deep-Breath\n",
    "        \"PlanSolve\"  # Plan-Solve\n",
    "    ]\n",
    "]\n",
    "\n",
    "# user types\n",
    "exp_names = [\"light\", \"heavy\"]\n",
    "\n",
    "# nDCG@k, Hit@k\n",
    "k = 3\n",
    "\n",
    "# set random seed\n",
    "utils.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea902c7c-4048-4d7a-ad30-4c9496475c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee19876-f4e4-4822-87fd-a3e14cceb24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prompt = {\n",
    "    \"UserSummarization\" : \"Summarize-User\",\n",
    "    \"ItemGenerateTrue\" : \"Reuse-Item\",\n",
    "    \"ItemGenerate\" : \"Generate-Item\",\n",
    "    \"Bothinst\" : \"Both-Inst\",\n",
    "    \"PlanSolve\" : \"Plan-Solve\",\n",
    "    \"StepBack\" : \"Step-Back\",\n",
    "    \"TakeBreath\" : \"Deep-Breath\",\n",
    "    \"RecencyFocused\" : \"Recency-Focused\",\n",
    "    \"ZSCoT\" : \"Step-by-Step\",\n",
    "    \"Pretend\" : \"RolePlay-User\",\n",
    "    \"Baseline_SystemRole\" : \"RolePlay-Expert\",\n",
    "    \"Baseline_Naming\" : \"RolePlay-Frederick\",\n",
    "    \"Baseline_ItemSummary\" : \"Summarize-Item\"\n",
    "}\n",
    "\n",
    "def _load_error(model_name, types_prompt):\n",
    "    llm = utils.load_llm(model_name)\n",
    "    \n",
    "    dict_error = dict()\n",
    "    for data_name in tqdm(data_names):\n",
    "        dict_error[data_name] = dict()\n",
    "        for exp_name in exp_names:\n",
    "    \n",
    "            dict_error[data_name][exp_name] = dict()\n",
    "            for type_prompt in types_prompt:\n",
    "                d_, path_log = main.run_single(\n",
    "                    llm=llm,\n",
    "                    model_name=model_name, \n",
    "                    data_name=data_name,\n",
    "                    version_infer=version_infer, \n",
    "                    n_user=n_user, \n",
    "                    exp_name=exp_name, \n",
    "                    type_prompt=type_prompt,\n",
    "                    version_input=version_input, \n",
    "                    version_prep=version_prep,\n",
    "                    n_user_exp=n_user_exp,\n",
    "                    for_error_analysis=True\n",
    "                )\n",
    "    \n",
    "                # load all generated text\n",
    "                llm.path_log = path_log\n",
    "                df_log = llm.load_log()\n",
    "    \n",
    "                # collect fail information\n",
    "                dt = dict()\n",
    "                users_failed = [user for user, d in d_.items() if \"F\" in d[\"pred\"]]\n",
    "                if len(users_failed) > 0:\n",
    "                    s_input = df_log[\"input text\"]\n",
    "                    s_output = df_log[\"output text\"]\n",
    "    \n",
    "                    n_retry = 5  \n",
    "                    consecutives = (s_input == s_input.shift())\n",
    "                    \n",
    "                    for i in range(2, n_retry + 1):\n",
    "                        consecutives &= (s_input == s_input.shift(i - 1))\n",
    "                    \n",
    "                    result_indices = consecutives.loc[consecutives].index - (n_retry - 1)\n",
    "                    unique_failed_indices = result_indices.unique()[-1*(len(users_failed)):]\n",
    "    \n",
    "                    for i, idx in enumerate(unique_failed_indices):\n",
    "                        dt[i] = {\n",
    "                            \"user\" : users_failed[i],\n",
    "                            \"thought\" : s_output.iloc[idx-1],\n",
    "                            \"answers\" : s_output.iloc[idx:idx+n].values\n",
    "                            }   \n",
    "                \n",
    "                # collect successful ranking results\n",
    "                tt = \"- Do not explain the reason and include any other words.\"  # words in final_task\n",
    "                idx = [i for i, t in enumerate(df_log[\"input text\"].drop_duplicates().values) if tt in t]\n",
    "                s = df_log[\"output text\"].iloc[idx]\n",
    "                \n",
    "                d = dict()\n",
    "                error_count = 0\n",
    "                for i, t in enumerate(s.values):\n",
    "                    try:\n",
    "                        l = [int(a) for a in t.split(\"[\")[1].split(\"]\")[0].replace(\"\\\\\", \"\").split(\",\")]\n",
    "                        n = len(l)\n",
    "                        if n <= 10 and n >= 1:\n",
    "                            d[i] = n\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # lendth of rankings; 10 means all items are sucessfully ranked\n",
    "                v = np.array(list(d.values()))  \n",
    "\n",
    "                if len(v) > 0:\n",
    "                    de = {\n",
    "                        3 : np.mean(v >= 3),\n",
    "                        5 : np.mean(v >= 5), \n",
    "                        10: np.mean(v == 10),\n",
    "                        \"F\" : len(users_failed) / len(d_)\n",
    "                    }\n",
    "                    de = pd.Series(de).fillna(0).to_dict()\n",
    "                else:\n",
    "                    de = {i : 0 for i in [3,5,10]}\n",
    "                    de[\"F\"] = 1\n",
    "                \n",
    "                de = {k : v for k,v in de.items()}\n",
    "                \n",
    "                type_prompt = type_prompt.split(\"_Method\")[1]\n",
    "                for k,v in d_prompt.items():\n",
    "                    try:\n",
    "                        type_prompt = type_prompt.replace(k,v)\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                dict_error[data_name][exp_name][type_prompt] = {\n",
    "                    \"stat\" : de, \n",
    "                    \"text\" : dt\n",
    "                }\n",
    "    return dict_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087cfbda-d232-4867-8499-7fcf8aed1f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-mini-2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 8/8 [00:41<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-3-70b-instruct-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 8/8 [00:39<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 8/8 [01:16<00:00,  9.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 8/8 [01:09<00:00,  8.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nova-lite-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 8/8 [00:43<00:00,  5.40s/it]\n"
     ]
    }
   ],
   "source": [
    "ddict_error = dict()\n",
    "for model_name, model_name_short in d_model.items():\n",
    "    print(model_name)\n",
    "    ddict_error[model_name_short] = _load_error(model_name, types_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d50b1d6-560a-4c29-8063-b6309cbcbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select mode\n",
    "# - \"latex\" will give all table info in latex format\n",
    "# - \"view\" will give all table info in pandas dataframe html style\n",
    "presentation = [\"latex\", \"view\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63318a07-34ef-43c5-8a1b-da5d3f21dcc4",
   "metadata": {},
   "source": [
    "# Section 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e480c77-af93-4754-8b3a-a3cea6611b1e",
   "metadata": {},
   "source": [
    "## Table 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ddcf22-58e4-4cac-8cca-36413c11a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4.1-mini</th>\n",
       "      <th>llama3.3-70b</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <th>phi4</th>\n",
       "      <th>amazon-nova-lite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.4 / 1.7$</td>\n",
       "      <td>$\\textbf{16.6} / \\textbf{12.5}$</td>\n",
       "      <td>$0.1 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 1.0$</td>\n",
       "      <td>$\\textbf{17.0} / \\textbf{12.6}$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re-Reading</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.4 / 2.1$</td>\n",
       "      <td>$\\textbf{46.1} / \\textbf{26.1}$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Both-Inst</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.4 / 1.0$</td>\n",
       "      <td>$\\textbf{16.4} / \\textbf{12.5}$</td>\n",
       "      <td>$0.1 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recency-Focused</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.8 / 2.1$</td>\n",
       "      <td>$\\textbf{18.0} / \\textbf{12.6}$</td>\n",
       "      <td>$0.1 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RolePlay-User</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$\\textbf{16.2} / \\textbf{12.5}$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RolePlay-Expert</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.4 / 1.3$</td>\n",
       "      <td>$\\textbf{16.6} / \\textbf{12.5}$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RolePlay-Frederick</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.5 / 1.6$</td>\n",
       "      <td>$\\textbf{16.2} / \\textbf{12.8}$</td>\n",
       "      <td>$0.1 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summarize-Item</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0.3$</td>\n",
       "      <td>$7.9 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step-Back</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 1.7$</td>\n",
       "      <td>$\\textbf{35.5} / \\textbf{13.6}$</td>\n",
       "      <td>$\\textbf{39.6} / 0.5$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReAct</th>\n",
       "      <td>$0.1 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$1.4 / \\textbf{21.5}$</td>\n",
       "      <td>$\\textbf{26.4} / \\textbf{15.1}$</td>\n",
       "      <td>$\\textbf{19.1} / 2.9$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rephrase</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.1 / 1.8$</td>\n",
       "      <td>$\\textbf{25.0} / \\textbf{14.1}$</td>\n",
       "      <td>$5.1 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Echo</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.5 / 2.2$</td>\n",
       "      <td>$\\textbf{44.9} / \\textbf{25.0}$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summarize-User</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.1 / 0.8$</td>\n",
       "      <td>$\\textbf{18.8} / \\textbf{13.0}$</td>\n",
       "      <td>$1.7 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generate-Item</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.2 / 1.0$</td>\n",
       "      <td>$\\textbf{24.3} / \\textbf{12.5}$</td>\n",
       "      <td>$0.2 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuse-Item</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 2.4$</td>\n",
       "      <td>$\\textbf{19.5} / \\textbf{12.6}$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explain</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0.2$</td>\n",
       "      <td>$\\textbf{23.1} / \\textbf{12.6}$</td>\n",
       "      <td>$0.1 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mock</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0.1 / 1.5$</td>\n",
       "      <td>$\\textbf{16.9} / \\textbf{12.5}$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step-by-Step</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 1.7$</td>\n",
       "      <td>$\\textbf{36.0} / \\textbf{13.5}$</td>\n",
       "      <td>$0.6 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep-Breath</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 1.7$</td>\n",
       "      <td>$\\textbf{39.1} / \\textbf{13.3}$</td>\n",
       "      <td>$0.4 / 0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plan-Solve</th>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 0$</td>\n",
       "      <td>$0 / 2.4$</td>\n",
       "      <td>$\\textbf{50.9} / \\textbf{14.1}$</td>\n",
       "      <td>$8.4 / 1.9$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   gpt-4.1-mini llama3.3-70b            gpt-4o-mini  \\\n",
       "Baseline                $0 / 0$      $0 / 0$            $0.4 / 1.7$   \n",
       "Emotion                 $0 / 0$      $0 / 0$              $0 / 1.0$   \n",
       "Re-Reading              $0 / 0$      $0 / 0$            $0.4 / 2.1$   \n",
       "Both-Inst               $0 / 0$      $0 / 0$            $0.4 / 1.0$   \n",
       "Recency-Focused         $0 / 0$      $0 / 0$            $0.8 / 2.1$   \n",
       "RolePlay-User           $0 / 0$      $0 / 0$              $0 / 0.1$   \n",
       "RolePlay-Expert         $0 / 0$      $0 / 0$            $0.4 / 1.3$   \n",
       "RolePlay-Frederick      $0 / 0$      $0 / 0$            $0.5 / 1.6$   \n",
       "Summarize-Item          $0 / 0$      $0 / 0$              $0 / 0.3$   \n",
       "Step-Back               $0 / 0$      $0 / 0$              $0 / 1.7$   \n",
       "ReAct                 $0.1 / 0$      $0 / 0$  $1.4 / \\textbf{21.5}$   \n",
       "Rephrase                $0 / 0$      $0 / 0$            $0.1 / 1.8$   \n",
       "Echo                    $0 / 0$      $0 / 0$            $0.5 / 2.2$   \n",
       "Summarize-User          $0 / 0$      $0 / 0$            $0.1 / 0.8$   \n",
       "Generate-Item           $0 / 0$      $0 / 0$            $0.2 / 1.0$   \n",
       "Reuse-Item              $0 / 0$      $0 / 0$              $0 / 2.4$   \n",
       "Explain                 $0 / 0$      $0 / 0$              $0 / 0.2$   \n",
       "Mock                    $0 / 0$      $0 / 0$            $0.1 / 1.5$   \n",
       "Step-by-Step            $0 / 0$      $0 / 0$              $0 / 1.7$   \n",
       "Deep-Breath             $0 / 0$      $0 / 0$              $0 / 1.7$   \n",
       "Plan-Solve              $0 / 0$      $0 / 0$              $0 / 2.4$   \n",
       "\n",
       "                                               phi4       amazon-nova-lite  \n",
       "Baseline            $\\textbf{16.6} / \\textbf{12.5}$              $0.1 / 0$  \n",
       "Emotion             $\\textbf{17.0} / \\textbf{12.6}$                $0 / 0$  \n",
       "Re-Reading          $\\textbf{46.1} / \\textbf{26.1}$                $0 / 0$  \n",
       "Both-Inst           $\\textbf{16.4} / \\textbf{12.5}$              $0.1 / 0$  \n",
       "Recency-Focused     $\\textbf{18.0} / \\textbf{12.6}$              $0.1 / 0$  \n",
       "RolePlay-User       $\\textbf{16.2} / \\textbf{12.5}$                $0 / 0$  \n",
       "RolePlay-Expert     $\\textbf{16.6} / \\textbf{12.5}$                $0 / 0$  \n",
       "RolePlay-Frederick  $\\textbf{16.2} / \\textbf{12.8}$              $0.1 / 0$  \n",
       "Summarize-Item                            $7.9 / 0$                $0 / 0$  \n",
       "Step-Back           $\\textbf{35.5} / \\textbf{13.6}$  $\\textbf{39.6} / 0.5$  \n",
       "ReAct               $\\textbf{26.4} / \\textbf{15.1}$  $\\textbf{19.1} / 2.9$  \n",
       "Rephrase            $\\textbf{25.0} / \\textbf{14.1}$              $5.1 / 0$  \n",
       "Echo                $\\textbf{44.9} / \\textbf{25.0}$                $0 / 0$  \n",
       "Summarize-User      $\\textbf{18.8} / \\textbf{13.0}$              $1.7 / 0$  \n",
       "Generate-Item       $\\textbf{24.3} / \\textbf{12.5}$              $0.2 / 0$  \n",
       "Reuse-Item          $\\textbf{19.5} / \\textbf{12.6}$                $0 / 0$  \n",
       "Explain             $\\textbf{23.1} / \\textbf{12.6}$              $0.1 / 0$  \n",
       "Mock                $\\textbf{16.9} / \\textbf{12.5}$                $0 / 0$  \n",
       "Step-by-Step        $\\textbf{36.0} / \\textbf{13.5}$              $0.6 / 0$  \n",
       "Deep-Breath         $\\textbf{39.1} / \\textbf{13.3}$              $0.4 / 0$  \n",
       "Plan-Solve          $\\textbf{50.9} / \\textbf{14.1}$            $8.4 / 1.9$  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# failure and lendth of rankings >= 3\n",
    "de = dict()\n",
    "for model_name, dict_error in ddict_error.items():\n",
    "    da = dict()\n",
    "    for data_name, d1 in dict_error.items():\n",
    "        for exp_name, d2 in d1.items():\n",
    "            db = dict()\n",
    "            for type_prompt, d3 in d2.items():\n",
    "                db[type_prompt] = d3[\"stat\"]\n",
    "    \n",
    "            df = pd.DataFrame(db)\n",
    "        da[f\"{data_name}_{exp_name}\"] = df\n",
    "\n",
    "    ds = dict()\n",
    "    for a in [3,5,10,\"F\"]:\n",
    "        d = dict()\n",
    "        for e, df in da.items():\n",
    "            d[e] = df.loc[a]\n",
    "    \n",
    "        ds[a] = pd.DataFrame(d).mean(axis=1)\n",
    "    df = pd.DataFrame(ds).T\n",
    "    de[model_name] = df\n",
    "\n",
    "# add \\textbf to emphasize error cases\n",
    "def _tmp(s):\n",
    "    s = s * 100\n",
    "    if s >= 10:\n",
    "        return \"\\\\textbf{\" + f\"{s:.1f}\" + \"}\"\n",
    "    elif s > 0:\n",
    "        return f\"{s:.1f}\"\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "d2 = dict()\n",
    "for model_name, df in de.items():\n",
    "    s3 = 1 - df.loc[3]\n",
    "    sf = df.loc[\"F\"]\n",
    "    d2[model_name] = \"$\" + sf.apply(_tmp) + \" / \" + s3.apply(_tmp) + \"$\" \n",
    "df = pd.DataFrame(d2)\n",
    "\n",
    "# Table 10 : failure and lendth of rankings >= 3\n",
    "if presentation == \"latex\":\n",
    "    print(df.to_latex(escape=False))\n",
    "else:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0700ab40-d648-423a-9243-6bf441c46c04",
   "metadata": {},
   "source": [
    "## Supplementary material (Table 17-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9dc1ce6-f552-49d2-be74-e230388d0beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4.1-mini</th>\n",
       "      <th>llama3.3-70b</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <th>phi4</th>\n",
       "      <th>amazon-nova-lite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$4.9 / 5.9$</td>\n",
       "      <td>$\\textbf{12.9} / \\textbf{13.5}$</td>\n",
       "      <td>$0.6 / 0.8$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$4.1 / 4.9$</td>\n",
       "      <td>$\\textbf{12.8} / \\textbf{13.0}$</td>\n",
       "      <td>$0.2 / 0.4$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re-Reading</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$\\textbf{15.6} / \\textbf{18.0}$</td>\n",
       "      <td>$\\textbf{27.8} / \\textbf{28.3}$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Both-Inst</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$2.8 / 3.6$</td>\n",
       "      <td>$\\textbf{13.4} / \\textbf{13.5}$</td>\n",
       "      <td>$0.6 / 0.8$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recency-Focused</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$6.2 / 6.9$</td>\n",
       "      <td>$\\textbf{12.9} / \\textbf{12.9}$</td>\n",
       "      <td>$0.5 / 0.6$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RolePlay-User</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0.4 / 0.8$</td>\n",
       "      <td>$\\textbf{12.6} / \\textbf{12.9}$</td>\n",
       "      <td>$0.1 / 0.2$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RolePlay-Expert</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$4.5 / 5.4$</td>\n",
       "      <td>$\\textbf{12.5} / \\textbf{12.9}$</td>\n",
       "      <td>$1.9 / 2.0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RolePlay-Frederick</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$4.6 / 5.4$</td>\n",
       "      <td>$\\textbf{13.4} / \\textbf{13.6}$</td>\n",
       "      <td>$0.8 / 0.9$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summarize-Item</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$1.6 / 2.5$</td>\n",
       "      <td>$0 / 1.1$</td>\n",
       "      <td>$1.0 / 1.1$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step-Back</th>\n",
       "      <td>$0 / 0.2$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$3.9 / 7.9$</td>\n",
       "      <td>$\\textbf{14.5} / \\textbf{15.6}$</td>\n",
       "      <td>$1.8 / 2.8$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReAct</th>\n",
       "      <td>$0 / 0.9$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$\\textbf{45.8} / \\textbf{62.7}$</td>\n",
       "      <td>$\\textbf{35.0} / \\textbf{40.4}$</td>\n",
       "      <td>$\\textbf{12.4} / \\textbf{16.7}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rephrase</th>\n",
       "      <td>$0 / 0.9$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$4.6 / 5.7$</td>\n",
       "      <td>$\\textbf{16.0} / \\textbf{16.5}$</td>\n",
       "      <td>$1.5 / 1.8$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Echo</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$\\textbf{12.6} / \\textbf{15.9}$</td>\n",
       "      <td>$\\textbf{25.0} / \\textbf{25.0}$</td>\n",
       "      <td>$0.1 / 0.2$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summarize-User</th>\n",
       "      <td>$0 / 2.6$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$3.8 / 7.3$</td>\n",
       "      <td>$\\textbf{13.3} / \\textbf{13.8}$</td>\n",
       "      <td>$0.1 / 0.7$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generate-Item</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$3.5 / 5.3$</td>\n",
       "      <td>$\\textbf{12.6} / \\textbf{13.3}$</td>\n",
       "      <td>$1.0 / 1.1$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuse-Item</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$\\textbf{11.1} / \\textbf{12.7}$</td>\n",
       "      <td>$\\textbf{14.3} / \\textbf{15.3}$</td>\n",
       "      <td>$\\textbf{12.6} / \\textbf{12.9}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explain</th>\n",
       "      <td>$0 / 0.2$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$1.4 / 6.2$</td>\n",
       "      <td>$\\textbf{12.7} / \\textbf{12.9}$</td>\n",
       "      <td>$0.5 / 0.9$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mock</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$\\textbf{10.2} / \\textbf{11.9}$</td>\n",
       "      <td>$\\textbf{12.6} / \\textbf{13.5}$</td>\n",
       "      <td>$1.6 / 1.9$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step-by-Step</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$5.2 / 6.5$</td>\n",
       "      <td>$\\textbf{17.5} / \\textbf{20.0}$</td>\n",
       "      <td>$0.5 / 0.6$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep-Breath</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$5.6 / 6.8$</td>\n",
       "      <td>$\\textbf{15.5} / \\textbf{18.0}$</td>\n",
       "      <td>$0.1 / 0.2$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plan-Solve</th>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$0 / 0.1$</td>\n",
       "      <td>$7.4 / 9.3$</td>\n",
       "      <td>$\\textbf{16.5} / \\textbf{18.3}$</td>\n",
       "      <td>$6.2 / 8.1$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   gpt-4.1-mini llama3.3-70b                      gpt-4o-mini  \\\n",
       "Baseline              $0 / 0.1$    $0 / 0.1$                      $4.9 / 5.9$   \n",
       "Emotion               $0 / 0.1$    $0 / 0.1$                      $4.1 / 4.9$   \n",
       "Re-Reading            $0 / 0.1$    $0 / 0.1$  $\\textbf{15.6} / \\textbf{18.0}$   \n",
       "Both-Inst             $0 / 0.1$    $0 / 0.1$                      $2.8 / 3.6$   \n",
       "Recency-Focused       $0 / 0.1$    $0 / 0.1$                      $6.2 / 6.9$   \n",
       "RolePlay-User         $0 / 0.1$    $0 / 0.1$                      $0.4 / 0.8$   \n",
       "RolePlay-Expert       $0 / 0.1$    $0 / 0.1$                      $4.5 / 5.4$   \n",
       "RolePlay-Frederick    $0 / 0.1$    $0 / 0.1$                      $4.6 / 5.4$   \n",
       "Summarize-Item        $0 / 0.1$    $0 / 0.1$                      $1.6 / 2.5$   \n",
       "Step-Back             $0 / 0.2$    $0 / 0.1$                      $3.9 / 7.9$   \n",
       "ReAct                 $0 / 0.9$    $0 / 0.1$  $\\textbf{45.8} / \\textbf{62.7}$   \n",
       "Rephrase              $0 / 0.9$    $0 / 0.1$                      $4.6 / 5.7$   \n",
       "Echo                  $0 / 0.1$    $0 / 0.1$  $\\textbf{12.6} / \\textbf{15.9}$   \n",
       "Summarize-User        $0 / 2.6$    $0 / 0.1$                      $3.8 / 7.3$   \n",
       "Generate-Item         $0 / 0.1$    $0 / 0.1$                      $3.5 / 5.3$   \n",
       "Reuse-Item            $0 / 0.1$    $0 / 0.1$  $\\textbf{11.1} / \\textbf{12.7}$   \n",
       "Explain               $0 / 0.2$    $0 / 0.1$                      $1.4 / 6.2$   \n",
       "Mock                  $0 / 0.1$    $0 / 0.1$  $\\textbf{10.2} / \\textbf{11.9}$   \n",
       "Step-by-Step          $0 / 0.1$    $0 / 0.1$                      $5.2 / 6.5$   \n",
       "Deep-Breath           $0 / 0.1$    $0 / 0.1$                      $5.6 / 6.8$   \n",
       "Plan-Solve            $0 / 0.1$    $0 / 0.1$                      $7.4 / 9.3$   \n",
       "\n",
       "                                               phi4  \\\n",
       "Baseline            $\\textbf{12.9} / \\textbf{13.5}$   \n",
       "Emotion             $\\textbf{12.8} / \\textbf{13.0}$   \n",
       "Re-Reading          $\\textbf{27.8} / \\textbf{28.3}$   \n",
       "Both-Inst           $\\textbf{13.4} / \\textbf{13.5}$   \n",
       "Recency-Focused     $\\textbf{12.9} / \\textbf{12.9}$   \n",
       "RolePlay-User       $\\textbf{12.6} / \\textbf{12.9}$   \n",
       "RolePlay-Expert     $\\textbf{12.5} / \\textbf{12.9}$   \n",
       "RolePlay-Frederick  $\\textbf{13.4} / \\textbf{13.6}$   \n",
       "Summarize-Item                            $0 / 1.1$   \n",
       "Step-Back           $\\textbf{14.5} / \\textbf{15.6}$   \n",
       "ReAct               $\\textbf{35.0} / \\textbf{40.4}$   \n",
       "Rephrase            $\\textbf{16.0} / \\textbf{16.5}$   \n",
       "Echo                $\\textbf{25.0} / \\textbf{25.0}$   \n",
       "Summarize-User      $\\textbf{13.3} / \\textbf{13.8}$   \n",
       "Generate-Item       $\\textbf{12.6} / \\textbf{13.3}$   \n",
       "Reuse-Item          $\\textbf{14.3} / \\textbf{15.3}$   \n",
       "Explain             $\\textbf{12.7} / \\textbf{12.9}$   \n",
       "Mock                $\\textbf{12.6} / \\textbf{13.5}$   \n",
       "Step-by-Step        $\\textbf{17.5} / \\textbf{20.0}$   \n",
       "Deep-Breath         $\\textbf{15.5} / \\textbf{18.0}$   \n",
       "Plan-Solve          $\\textbf{16.5} / \\textbf{18.3}$   \n",
       "\n",
       "                                   amazon-nova-lite  \n",
       "Baseline                                $0.6 / 0.8$  \n",
       "Emotion                                 $0.2 / 0.4$  \n",
       "Re-Reading                                $0 / 0.1$  \n",
       "Both-Inst                               $0.6 / 0.8$  \n",
       "Recency-Focused                         $0.5 / 0.6$  \n",
       "RolePlay-User                           $0.1 / 0.2$  \n",
       "RolePlay-Expert                         $1.9 / 2.0$  \n",
       "RolePlay-Frederick                      $0.8 / 0.9$  \n",
       "Summarize-Item                          $1.0 / 1.1$  \n",
       "Step-Back                               $1.8 / 2.8$  \n",
       "ReAct               $\\textbf{12.4} / \\textbf{16.7}$  \n",
       "Rephrase                                $1.5 / 1.8$  \n",
       "Echo                                    $0.1 / 0.2$  \n",
       "Summarize-User                          $0.1 / 0.7$  \n",
       "Generate-Item                           $1.0 / 1.1$  \n",
       "Reuse-Item          $\\textbf{12.6} / \\textbf{12.9}$  \n",
       "Explain                                 $0.5 / 0.9$  \n",
       "Mock                                    $1.6 / 1.9$  \n",
       "Step-by-Step                            $0.5 / 0.6$  \n",
       "Deep-Breath                             $0.1 / 0.2$  \n",
       "Plan-Solve                              $6.2 / 8.1$  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# endth of rankings >= 5 and == 10\n",
    "def _tmp(s):\n",
    "    s = s * 100\n",
    "    if s >= 10:\n",
    "        return \"\\\\textbf{\" + f\"{s:.1f}\" + \"}\"\n",
    "    elif s > 0:\n",
    "        return f\"{s:.1f}\"\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "\n",
    "d2 = dict()\n",
    "for model_name, df in de.items():\n",
    "    s5 = 1 - df.loc[5]\n",
    "    s10 = 1 - df.loc[10]\n",
    "    d2[model_name] = \"$\" + s5.apply(_tmp) + \" / \" + s10.apply(_tmp) + \"$\" \n",
    "df = pd.DataFrame(d2)\n",
    "if presentation == \"latex\":\n",
    "    print(df.to_latex(escape=False))\n",
    "else:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd05bae-003a-4968-9235-638603d1fe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Light</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Heavy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yelp</th>\n",
       "      <td>9662</td>\n",
       "      <td>2959</td>\n",
       "      <td>6218.2</td>\n",
       "      <td>1199.7</td>\n",
       "      <td>48660</td>\n",
       "      <td>13363</td>\n",
       "      <td>24749.6</td>\n",
       "      <td>4674.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>1966</td>\n",
       "      <td>1227</td>\n",
       "      <td>1537.3</td>\n",
       "      <td>151.3</td>\n",
       "      <td>5516</td>\n",
       "      <td>2932</td>\n",
       "      <td>3890.8</td>\n",
       "      <td>495.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>6218</td>\n",
       "      <td>3991</td>\n",
       "      <td>4859.1</td>\n",
       "      <td>353.2</td>\n",
       "      <td>18552</td>\n",
       "      <td>12373</td>\n",
       "      <td>15463.6</td>\n",
       "      <td>1117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie</th>\n",
       "      <td>3573</td>\n",
       "      <td>1121</td>\n",
       "      <td>2146.0</td>\n",
       "      <td>487.3</td>\n",
       "      <td>13282</td>\n",
       "      <td>3173</td>\n",
       "      <td>6793.2</td>\n",
       "      <td>1964.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>3884</td>\n",
       "      <td>1038</td>\n",
       "      <td>1943.1</td>\n",
       "      <td>465.5</td>\n",
       "      <td>12315</td>\n",
       "      <td>2767</td>\n",
       "      <td>6579.7</td>\n",
       "      <td>2180.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Groceries</th>\n",
       "      <td>4427</td>\n",
       "      <td>1668</td>\n",
       "      <td>2921.1</td>\n",
       "      <td>533.8</td>\n",
       "      <td>15994</td>\n",
       "      <td>5453</td>\n",
       "      <td>9414.0</td>\n",
       "      <td>2211.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clothes</th>\n",
       "      <td>4050</td>\n",
       "      <td>1340</td>\n",
       "      <td>2571.5</td>\n",
       "      <td>486.4</td>\n",
       "      <td>14379</td>\n",
       "      <td>3905</td>\n",
       "      <td>7168.7</td>\n",
       "      <td>1794.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book</th>\n",
       "      <td>4316</td>\n",
       "      <td>1004</td>\n",
       "      <td>1896.2</td>\n",
       "      <td>527.5</td>\n",
       "      <td>12014</td>\n",
       "      <td>3007</td>\n",
       "      <td>6477.8</td>\n",
       "      <td>1764.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Light                        Heavy                        \n",
       "            max   min    mean     std    max    min     mean     std\n",
       "Yelp       9662  2959  6218.2  1199.7  48660  13363  24749.6  4674.3\n",
       "News       1966  1227  1537.3   151.3   5516   2932   3890.8   495.5\n",
       "Food       6218  3991  4859.1   353.2  18552  12373  15463.6  1117.0\n",
       "Movie      3573  1121  2146.0   487.3  13282   3173   6793.2  1964.9\n",
       "Music      3884  1038  1943.1   465.5  12315   2767   6579.7  2180.9\n",
       "Groceries  4427  1668  2921.1   533.8  15994   5453   9414.0  2211.5\n",
       "Clothes    4050  1340  2571.5   486.4  14379   3905   7168.7  1794.8\n",
       "Book       4316  1004  1896.2   527.5  12014   3007   6477.8  1764.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# token length statistics Baseline\n",
    "d_data = {\n",
    "    \"Amazon_Music\" : \"Music\",\n",
    "    \"Amazon_Movie\" : \"Movie\",\n",
    "    \"Amazon_Grocery\" : \"Groceries\",\n",
    "    \"Amazon_Clothes\" : \"Clothes\",\n",
    "    \"Amazon_Book\" : \"Book\",\n",
    "    \"Yelp\" : \"Yelp\",\n",
    "    \"MIND\" : \"News\",\n",
    "    \"Food\" : \"Food\"\n",
    "}\n",
    "\n",
    "d_exp = {\n",
    "    \"light\" : \"Light\",\n",
    "    \"heavy\" : \"Heavy\"\n",
    "}\n",
    "\n",
    "\n",
    "model_name = \"gpt-4o-mini-2024-07-18\"\n",
    "llm = utils.load_llm(model_name)\n",
    "\n",
    "dict_token= dict()\n",
    "for data_name in data_names:\n",
    "    dict_token[data_name] = dict()\n",
    "    for exp_name in exp_names:\n",
    "        for type_prompt in [\"ItemAll_MethodBaseline\"]:\n",
    "            d_, path_log = main.run_single(\n",
    "                llm=llm,\n",
    "                model_name=model_name, \n",
    "                data_name=data_name,\n",
    "                version_infer=version_infer, \n",
    "                n_user=n_user, \n",
    "                exp_name=exp_name, \n",
    "                type_prompt=type_prompt,\n",
    "                version_input=version_input, \n",
    "                version_prep=version_prep,\n",
    "                n_user_exp=n_user_exp,\n",
    "                for_error_analysis=True\n",
    "            )\n",
    "\n",
    "            # load all generated text\n",
    "            llm.path_log = path_log\n",
    "            df_log = llm.load_log()\n",
    "\n",
    "            tt = \"- Do not explain the reason and include any other words.\"\n",
    "            idx = [i for i, t in enumerate(df_log[\"input text\"].drop_duplicates().values) if tt in t]\n",
    "            s = df_log.iloc[idx][\"input token\"]\n",
    "            dict_token[data_name][exp_name] = s\n",
    "\n",
    "\n",
    "dss = dict()\n",
    "for exp_name in exp_names:\n",
    "    ds = dict()\n",
    "    for data_name in data_names:\n",
    "        s = dict_token[data_name][exp_name]\n",
    "        ds[d_data[data_name]]= {\n",
    "            \"max\" : f\"{int(s.max())}\", \n",
    "            \"min\" : f\"{int(s.min())}\",\n",
    "            \"mean\" : f\"{s.mean():.1f}\",\n",
    "            \"std\" : f\"{s.std():.1f}\"\n",
    "        }\n",
    "    df = pd.DataFrame(ds).T\n",
    "    dss[d_exp[exp_name]] = df\n",
    "df = pd.concat(dss, axis=1)\n",
    "if presentation == \"latex\":\n",
    "    print(df.to_latex(escape=False))\n",
    "else:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a471676e-0c3d-49f5-97ae-2bf038160c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Light</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Heavy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yelp</th>\n",
       "      <td>7735</td>\n",
       "      <td>3464</td>\n",
       "      <td>4685.1</td>\n",
       "      <td>703.0</td>\n",
       "      <td>41732</td>\n",
       "      <td>12718</td>\n",
       "      <td>17863.0</td>\n",
       "      <td>3784.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>2670</td>\n",
       "      <td>1894</td>\n",
       "      <td>2285.6</td>\n",
       "      <td>176.9</td>\n",
       "      <td>7277</td>\n",
       "      <td>4776</td>\n",
       "      <td>5974.3</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>5461</td>\n",
       "      <td>3716</td>\n",
       "      <td>4198.0</td>\n",
       "      <td>271.3</td>\n",
       "      <td>16199</td>\n",
       "      <td>10683</td>\n",
       "      <td>13388.6</td>\n",
       "      <td>1029.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie</th>\n",
       "      <td>4807</td>\n",
       "      <td>2299</td>\n",
       "      <td>3050.8</td>\n",
       "      <td>435.3</td>\n",
       "      <td>16693</td>\n",
       "      <td>6427</td>\n",
       "      <td>9431.4</td>\n",
       "      <td>2106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>4936</td>\n",
       "      <td>2317</td>\n",
       "      <td>3048.5</td>\n",
       "      <td>452.6</td>\n",
       "      <td>16820</td>\n",
       "      <td>6124</td>\n",
       "      <td>9952.4</td>\n",
       "      <td>2374.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Groceries</th>\n",
       "      <td>4160</td>\n",
       "      <td>2426</td>\n",
       "      <td>3064.5</td>\n",
       "      <td>398.0</td>\n",
       "      <td>16654</td>\n",
       "      <td>6605</td>\n",
       "      <td>9706.0</td>\n",
       "      <td>2059.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clothes</th>\n",
       "      <td>4328</td>\n",
       "      <td>2125</td>\n",
       "      <td>2751.8</td>\n",
       "      <td>384.5</td>\n",
       "      <td>14796</td>\n",
       "      <td>5884</td>\n",
       "      <td>8092.4</td>\n",
       "      <td>1588.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book</th>\n",
       "      <td>5287</td>\n",
       "      <td>2369</td>\n",
       "      <td>3104.1</td>\n",
       "      <td>517.2</td>\n",
       "      <td>16754</td>\n",
       "      <td>6367</td>\n",
       "      <td>9881.5</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Light                       Heavy                        \n",
       "            max   min    mean    std    max    min     mean     std\n",
       "Yelp       7735  3464  4685.1  703.0  41732  12718  17863.0  3784.7\n",
       "News       2670  1894  2285.6  176.9   7277   4776   5974.3   650.0\n",
       "Food       5461  3716  4198.0  271.3  16199  10683  13388.6  1029.1\n",
       "Movie      4807  2299  3050.8  435.3  16693   6427   9431.4  2106.2\n",
       "Music      4936  2317  3048.5  452.6  16820   6124   9952.4  2374.8\n",
       "Groceries  4160  2426  3064.5  398.0  16654   6605   9706.0  2059.7\n",
       "Clothes    4328  2125  2751.8  384.5  14796   5884   8092.4  1588.4\n",
       "Book       5287  2369  3104.1  517.2  16754   6367   9881.5  1995.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# token length statistics Summarize-Item\n",
    "\n",
    "model_name = \"gpt-4o-mini-2024-07-18\"\n",
    "llm = utils.load_llm(model_name)\n",
    "\n",
    "dict_token= dict()\n",
    "for data_name in data_names:\n",
    "    dict_token[data_name] = dict()\n",
    "    for exp_name in exp_names:\n",
    "        for type_prompt in [\"ItemAll_MethodBaseline_ItemSummary\"]:\n",
    "            d_, path_log = main.run_single(\n",
    "                llm=llm,\n",
    "                model_name=model_name, \n",
    "                data_name=data_name,\n",
    "                version_infer=version_infer, \n",
    "                n_user=n_user, \n",
    "                exp_name=exp_name, \n",
    "                type_prompt=type_prompt,\n",
    "                version_input=version_input, \n",
    "                version_prep=version_prep,\n",
    "                n_user_exp=n_user_exp,\n",
    "                for_error_analysis=True\n",
    "            )\n",
    "\n",
    "            # load all generated text\n",
    "            llm.path_log = path_log\n",
    "            df_log = llm.load_log()\n",
    "\n",
    "            tt = \"- Do not explain the reason and include any other words.\"\n",
    "            idx = [i for i, t in enumerate(df_log[\"input text\"].drop_duplicates().values) if tt in t]\n",
    "            s = df_log.iloc[idx][\"input token\"]\n",
    "            dict_token[data_name][exp_name] = s\n",
    "\n",
    "\n",
    "dss = dict()\n",
    "for exp_name in exp_names:\n",
    "    ds = dict()\n",
    "    for data_name in data_names:\n",
    "        s = dict_token[data_name][exp_name]\n",
    "        ds[d_data[data_name]]= {\n",
    "            \"max\" : f\"{int(s.max())}\", \n",
    "            \"min\" : f\"{int(s.min())}\",\n",
    "            \"mean\" : f\"{s.mean():.1f}\",\n",
    "            \"std\" : f\"{s.std():.1f}\"\n",
    "        }\n",
    "    df = pd.DataFrame(ds).T\n",
    "    dss[d_exp[exp_name]] = df\n",
    "df = pd.concat(dss, axis=1)\n",
    "if presentation == \"latex\":\n",
    "    print(df.to_latex(escape=False))\n",
    "else:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f89529-9c62-406d-b162-31ad5145b39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35714f9d-0f99-4509-8e66-aa19c13776b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53913e7-c590-46de-933f-fc1bce200324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d520262c-666f-4ff0-a878-76004d7bb906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"### Observation:\n",
      "The user has a history of reviewing ballet and dance-related workout DVDs. They express a strong preference for challenging workouts that provide effective results, particularly in toning and defining muscles. The user has rated several products, with the highest rating being 5.0 for a challenging ballet workout, while others received lower ratings due to being too easy or not effective enough.\n",
      "\n",
      "### Thought:\n",
      "The user seems to prefer products that are intense and provide a good workout, particularly in ballet and dance fitness. They have explicitly mentioned the need for challenging workouts that yield visible results. Therefore, any candidate products that align with these preferences, especially in the fitness category, would likely be more appealing to the user.\n",
      "\n",
      "### Action:\n",
      "I will examine the candidate products to identify any that align with the user's preferences for challenging workouts, particularly in the exercise and fitness category.\n",
      "\n",
      "1. **Emmet Otter's Jug-Band Christmas** - Not related to fitness.\n",
      "2. **The Stilwell Road** - Not related to fitness.\n",
      "3. **Shogun** - Not related to fitness.\n",
      "4. **Traitor** - Not related to fitness.\n",
      "5. **24 - Season 7** - Not related to fitness.\n",
      "6. **Bridesmaids** - Not related to fitness.\n",
      "7. **Hansel & Gretel: Witch Hunters** - Not related to fitness.\n",
      "8. **Heaven's Lost Property Forte: Season 2** - Not related to fitness.\n",
      "9. **Tracy Anderson: Precision Toning** - This is a fitness DVD, but given the user's feedback on other Tracy Anderson products being too easy, it may not meet their preference for challenging workouts.\n",
      "10. **Royal Paintbox** - Not related to fitness.\n",
      "\n",
      "### Observation:\n",
      "Among the candidate products, only **Tracy Anderson: Precision Toning** is related to fitness. However, based on the user's previous experiences with Tracy Anderson's workouts, they found them too easy. The other products do not align with the user's interests in ballet or challenging fitness routines.\n",
      "\n",
      "### Thought:\n",
      "Since there is only one candidate product related to fitness, and it does not align with the user's preference for challenging workouts, I must conclude that there are no suitable recommendations from the provided candidates.\n",
      "\n",
      "### Answer:\n",
      "Since none of the candidate products align with the user's preferences for challenging ballet or dance workouts, the final answer is: **[]** (no suitable recommendations).\"\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"### Observation\n",
      "The user's history shows a strong preference for Westerns, with all the previously reviewed products being Western films that have received high ratings (5.0). The reviews indicate a fondness for classic Western themes, character-driven narratives, and engaging plots, even if they are not considered top-tier Westerns.\n",
      "\n",
      "### Thought\n",
      "Given the user's clear inclination towards Westerns, it is essential to prioritize candidate products that align with this genre. The user seems to appreciate both well-known classics and lesser-known B-Westerns, as indicated by their enjoyment of films that may not be critically acclaimed but are still entertaining.\n",
      "\n",
      "### Action\n",
      "Now, I will examine the candidate items one by one, focusing on their characteristics and how they align with the user's preferences.\n",
      "\n",
      "1. **Under One Roof**: Comedy, not related to Westerns.\n",
      "2. **Deadly Blessing**: No description provided, but not a Western.\n",
      "3. **Audubon's VideoGuide to Birds of North America II**: Nature documentary, not related to Westerns.\n",
      "4. **Profile Of A Serial Killer**: Crime drama, not related to Westerns.\n",
      "5. **Film Noir Double Feature: Please Murder Me / A Life At Stake**: Film noir, not related to Westerns.\n",
      "6. **Rossini - La Cenerentola**: Opera, not related to Westerns.\n",
      "7. **Bright Star**: No description provided, but not a Western.\n",
      "8. **Dog Who Saved Halloween, The**: Family film, not related to Westerns.\n",
      "9. **Killer Holiday Digital**: Horror, not related to Westerns.\n",
      "10. **Zootopia**: Animated comedy, not related to Westerns.\n",
      "\n",
      "### Observation\n",
      "None of the candidate products are Westerns or closely related to the user's preferences. They all fall into different genres such as comedy, horror, family, and crime drama.\n",
      "\n",
      "### Thought\n",
      "Since none of the candidate products align with the user's strong preference for Westerns, I need to conclude that there are no suitable recommendations from this list.\n",
      "\n",
      "### Answer\n",
      "Given the lack of suitable Western options in the candidate products, I would recommend an empty list: [].\"\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Movie light ReAct\n",
      "====================================================================================================\n",
      "'[3,8,1,10,2,5,4,6,7,9]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Music heavy RolePlay-Frederick\n",
      "====================================================================================================\n",
      "'# Task Overview:\n",
      "You are required to rank a set of candidate products based on their alignment with a target user\\'s preferences. This involves analyzing the provided product information, including titles, categories, descriptions, ratings, and reviews, to determine which products are most suitable for the user. \n",
      "\n",
      "# User Preferences:\n",
      "The user has shown a strong inclination towards Classic Rock and Album-Oriented Rock (AOR) genres, as evidenced by the detailed descriptions and high ratings of the products previously listed. The user appreciates albums that feature classic rock elements, strong vocals, and engaging performances. \n",
      "\n",
      "# Candidate Products:\n",
      "You will be given a new set of candidate products, each with its own title, categories, and descriptions. Your task is to evaluate these products and rank them according to how closely they align with the user\\'s preferences for Classic Rock and AOR music.\n",
      "\n",
      "# Ranking Criteria:\n",
      "1. **Genre Alignment**: Products that fall under Classic Rock or AOR will be prioritized.\n",
      "2. **Rating**: Higher-rated products will be favored.\n",
      "3. **Descriptive Quality**: Products with detailed and positive reviews indicating strong performances or nostalgic value will be ranked higher.\n",
      "\n",
      "# Final Output:\n",
      "After evaluating the candidate products, you will present your rankings in the specified format. For example, if the top three products are ranked as second, first, and third, your output should be formatted as [2, 1, 3].\n",
      "\n",
      "# Candidates Products:\n",
      "The following candidate products need to be ranked based on the criteria outlined above:\n",
      "1. \\'Panther: The Soundtrack\\' - Categories: Rap & Hip-Hop, Pop Rap\n",
      "2. \\'Lesson to Be Learned\\' - Categories: R&B, Soul\n",
      "3. \\'Tarantism\\' - Categories: Pop\n",
      "4. \\'Return to Olympus\\' - Categories: Alternative Rock, American Alternative\n",
      "5. \\'Hymns\\' - Categories: Alternative Rock\n",
      "6. \"Songs from Andrew Lloyd Webber and Jim Steinman\\'s \\'Whistle Down the Wind\\'\" - Categories: Rock, Progressive, Progressive Rock\n",
      "7. \\'Sibelius: Symphonies No. 2 in D, & No. 7 in C\\' - Categories: Classical, Symphonies\n",
      "8. \\'Night Train To Nashville\\' - Categories: Blues, Regional Blues, New Orleans Blues\n",
      "9. \\'Front Street\\' - Categories: Jazz, Smooth Jazz\n",
      "10. \\'Complete Blue Note Collection: 1957-1960\\' - Categories: Jazz\n",
      "\n",
      "Your task is to analyze these products and provide a ranked list that reflects the user\\'s preferences for Classic Rock and AOR music. Please proceed with the evaluation and present your rankings accordingly.'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Music heavy Rephrase\n",
      "====================================================================================================\n",
      "'[2,3,4]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Music heavy Echo\n",
      "====================================================================================================\n",
      "\"### Step-by-Step Process\n",
      "\n",
      "**Observation:**  \n",
      "The user's history shows a strong preference for high-quality men's footwear, particularly sneakers, hiking shoes, and casual shoes. The products they have rated highly are all well-made, comfortable, and practical for everyday use. The user also seems to appreciate brands known for their durability and comfort, such as PUMA and Hi-Tec.\n",
      "\n",
      "**Thought:**  \n",
      "Given this history, the user is likely looking for products that are comfortable, durable, and suitable for various activities, including casual wear and outdoor activities. They seem to prefer items with high ratings and positive reviews, indicating satisfaction with the product's quality and fit.\n",
      "\n",
      "**Action:**  \n",
      "I will evaluate each candidate item based on its characteristics, focusing particularly on footwear, as that aligns closely with the user's previous purchases.\n",
      "\n",
      "1. **KEEN Men's Newport Sandal**  \n",
      "   - **Categories:** Men, Shoes, Sandals  \n",
      "   - **Description:** Comfortable fit with a secure strap design and good traction.  \n",
      "   - **Rating:** Not provided.  \n",
      "   - **Thought:** This sandal is practical for outdoor activities, but it may not align with the user's preference for closed footwear.\n",
      "\n",
      "2. **Hanes Sport Low Impact Sports Bras**  \n",
      "   - **Categories:** Women, Clothing, Lingerie  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "3. **Soft Comical Boxers for Men by LazyOne**  \n",
      "   - **Categories:** Novelty, Clothing, Underwear  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "4. **Michael Kors Pippa Sunglasses**  \n",
      "   - **Categories:** Women, Accessories  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "5. **Jockey Women's Underwear Plus Size Elance French Cut**  \n",
      "   - **Categories:** Women, Clothing, Lingerie  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "6. **Calvin Klein Jeans Women's Susie Boot**  \n",
      "   - **Categories:** Women, Shoes, Boots  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "7. **Sanuk Women's Yoga X-HALE Flip Flop**  \n",
      "   - **Categories:** Women, Shoes, Sandals  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "8. **V.H.O. Funky Hawaiian Shirt Men Short-Sleeve**  \n",
      "   - **Categories:** Men, Clothing, Shirts  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "9. **Women's Fashion Calf Flat Heel Side Zipper Slouch Ankle Boots**  \n",
      "   - **Categories:** Women, Shoes, Boots  \n",
      "   - **Thought:** Not relevant to the user's preferences.\n",
      "\n",
      "10. **NDB Men's Classical Comfortable II Flip-Flop**  \n",
      "    - **Categories:** Men, Shoes, Sandals  \n",
      "    - **Thought:** This is a sandal, which may not be the best fit for the user's preference for closed shoes.\n",
      "\n",
      "### Final Evaluation\n",
      "After evaluating all candidate items, it is clear that none of the candidates align closely with the user's established preferences for high-quality men's footwear. Most items are either irrelevant or targeted towards women.\n",
      "\n",
      "**Answer:**  \n",
      "Since there are no suitable candidates based on the user's preferences, I would recommend no items from the current selection.\"\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Clothes heavy ReAct\n",
      "====================================================================================================\n",
      "'[7, 4, 8, 1, 2, 3, 9, 10, 5, 6]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'[2,4,1,6,3,7,8,5,9,10]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Book heavy Both-Inst\n",
      "====================================================================================================\n",
      "'[3,2,1,9,8,4,5,6,10,7]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'[6,1,9,4,2,3,5,7,8,10]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'[3,6,1,2,5,4,7,8,9,10]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Book heavy Recency-Focused\n",
      "====================================================================================================\n",
      "\"### Observation:\n",
      "The user has a strong interest in cookbooks, particularly those related to diets (like Keto and Mediterranean), meal prep, and pressure cooking. The majority of the candidate products provided are unrelated to cooking or diet, focusing instead on fiction, politics, and other genres.\n",
      "\n",
      "### Thought:\n",
      "Given the user's preference for cookbooks, especially those that assist with diet and meal preparation, it is likely that they would be less interested in the fiction and political titles. The user seems to appreciate practical, informative, and easy-to-follow guides that help with cooking and healthy eating.\n",
      "\n",
      "### Action:\n",
      "Let's examine the candidate items one by one to determine if any align with the user's preferences.\n",
      "\n",
      "1. **Five Patients** - Focuses on emergency room stories; not related to cooking or diet.\n",
      "2. **The Prometheus Project: Trapped** - A children's science fiction book; not related to cooking or diet.\n",
      "3. **Beach Money; Creating Your Dream Life Through Network Marketing** - Business-related; not related to cooking or diet.\n",
      "4. **Swan And The Bear: Furry United Coalition** - Fiction; not related to cooking or diet.\n",
      "5. **Hawthorne** - Romance; not related to cooking or diet.\n",
      "6. **Lava Dawgs: A Fight for Fallujah** - Military history; not related to cooking or diet.\n",
      "7. **The Air He Breathes (Elements)** - Contemporary romance; not related to cooking or diet.\n",
      "8. **Survival Medicine & First Aid: The Leading Prepper's Guide to Survive Medical Emergencies in Tough Survival Situations** - While this is about survival, it does not focus on cooking or diet.\n",
      "9. **Graveyard Druid: A New Adult Urban Fantasy Novel** - Fiction; not related to cooking or diet.\n",
      "10. **Cruel and Usual Punishment** - Politics; not related to cooking or diet.\n",
      "\n",
      "### Observation:\n",
      "None of the candidate items align with the user's preferences for cookbooks or diet-related content.\n",
      "\n",
      "### Thought:\n",
      "Since all candidate items are unrelated to the user's interests, it is clear that none of these products would be suitable recommendations.\n",
      "\n",
      "### Answer:\n",
      "[ ]\"\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[ ]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"### Step-by-Step Process\n",
      "\n",
      "**Observation:** The user's history shows a strong preference for romance novels, particularly those with high ratings (mostly 5.0) and engaging character dynamics. The user enjoys contemporary romance, romantic comedies, and stories with emotional depth and character development.\n",
      "\n",
      "**Thought:** Given the user's preferences, I should focus on candidate products that align with the romance genre, particularly those that may have strong character interactions or emotional narratives. Other genres like literature and fiction may not align as closely with the user's evident interest in romance.\n",
      "\n",
      "### Evaluation of Candidate Products\n",
      "\n",
      "1. **The Midwife of Hope River: A Novel of an American Midwife**\n",
      "   - **Categories:** Literature & Fiction, Genre Fiction\n",
      "   - **Analysis:** This is a historical fiction novel and does not align with the user's romance preference.\n",
      "\n",
      "2. **Everything's an Argument with Readings: With 2001 APA Update**\n",
      "   - **Categories:** Reference, Writing, Research & Publishing Guides\n",
      "   - **Analysis:** This is an academic text and does not align with the user's preferences.\n",
      "\n",
      "3. **Blue Moo: 17 Jukebox Hits From Way Back Never**\n",
      "   - **Categories:** Children's Books, Arts, Music & Photography\n",
      "   - **Analysis:** This is a children's book and does not align with the user's preferences.\n",
      "\n",
      "4. **Your People Shall Be My People: How Israel, the Jews and the Christian Church Will Come Together in the Last Days**\n",
      "   - **Categories:** Christian Books & Bibles, Christian Living\n",
      "   - **Analysis:** This is a religious text and does not align with the user's preferences.\n",
      "\n",
      "5. **Merl Reagle's Sunday Crosswords, Vol. 1**\n",
      "   - **Categories:** Humor & Entertainment, Puzzles & Games\n",
      "   - **Analysis:** This is a puzzle book and does not align with the user's preferences.\n",
      "\n",
      "6. **Advantage Disadvantage**\n",
      "   - **Categories:** Literature & Fiction, Genre Fiction\n",
      "   - **Analysis:** This is a general fiction book and does not align with the user's preferences.\n",
      "\n",
      "7. **JET - Ops Files**\n",
      "   - **Categories:** Literature & Fiction, Action & Adventure\n",
      "   - **Analysis:** This is an action/adventure book and does not align with the user's preferences.\n",
      "\n",
      "8. **The Secret: What Great Leaders Know--and Do**\n",
      "   - **Categories:** Business & Money, Management & Leadership\n",
      "   - **Analysis:** This is a business book and does not align with the user's preferences.\n",
      "\n",
      "9. **Chosen: Curse of the Draekon Book One (Volume 1)**\n",
      "   - **Categories:** Science Fiction & Fantasy, Fantasy\n",
      "   - **Analysis:** This is a fantasy book and does not align with the user's preferences.\n",
      "\n",
      "10. **The Ultimate Calorie, Carb, and Fat Gram Counter**\n",
      "    - **Categories:** Health, Fitness & Dieting, Diseases & Physical Ailments\n",
      "    - **Analysis:** This is a health and diet book and does not align with the user's preferences.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "After evaluating all candidate products, none of them align with the user's strong preference for romance novels. Therefore, I cannot provide a ranked list of products based on the user's preferences.\n",
      "\n",
      "**Answer:** []\"\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"### Step 1: Observation\n",
      "The user's history shows a strong preference for children's books, particularly those that are educational, culturally enriching, or related to holidays and celebrations. The user also appreciates cookbooks, especially those that are easy to follow and cater to specific dietary needs. There is a notable interest in travel literature, particularly guides that provide practical information and insights.\n",
      "\n",
      "### Step 2: Thought\n",
      "Given the user's preferences, the ideal candidate products would likely be children's books that promote cultural understanding or educational themes, cookbooks that are user-friendly, and travel guides that offer insightful information. \n",
      "\n",
      "### Step 3: Action\n",
      "Let's examine the candidate items one by one to see which align best with the user's preferences.\n",
      "\n",
      "1. **The Life-Changing Magic of Tidying: A simple, effective way to banish clutter forever**\n",
      "   - **Categories**: Self-Help\n",
      "   - **Description**: Focuses on decluttering and organizing.\n",
      "   - **Thought**: While this book may appeal to some users interested in self-improvement, it does not align closely with the user's strong preference for children's literature or cookbooks.\n",
      "\n",
      "2. **The Island of Dr Moreau (Penguin Classics)**\n",
      "   - **Categories**: Literature & Fiction, History & Criticism\n",
      "   - **Thought**: This classic novel may not resonate with the user’s interests, as it is more focused on adult fiction rather than children's literature or cookbooks.\n",
      "\n",
      "3. **Krispos of Videssos (Tale of Krispos, No 2)**\n",
      "   - **Categories**: Literature & Fiction, Genre Fiction\n",
      "   - **Thought**: Similar to the previous item, this is a work of fiction that does not align with the user’s preferences for children's books or cookbooks.\n",
      "\n",
      "4. **A Second Chance**\n",
      "   - **Categories**: Literature & Fiction, Erotica\n",
      "   - **Thought**: This book does not match the user's interests, which lean towards children's literature and educational content.\n",
      "\n",
      "5. **Daddy's Girl**\n",
      "   - **Categories**: Romance, Contemporary\n",
      "   - **Thought**: Again, this does not align with the user’s preferences for children's books or cookbooks.\n",
      "\n",
      "6. **Must Remember**\n",
      "   - **Categories**: Romance, Paranormal\n",
      "   - **Thought**: This book does not fit the user's interests.\n",
      "\n",
      "7. **Walking with Purpose: Seven Priorities That Make Life Work**\n",
      "   - **Categories**: Self-Help, Relationships\n",
      "   - **Thought**: While potentially useful, this book does not align with the user’s strong preference for children's literature or cookbooks.\n",
      "\n",
      "8. **The Medici Boy**\n",
      "   - **Categories**: Lesbian, Gay, Bisexual & Transgender Books, Literature & Fiction\n",
      "   - **Thought**: This book does not match the user's interests.\n",
      "\n",
      "9. **The Only One: A One Love Novella**\n",
      "   - **Categories**: Romance, Contemporary\n",
      "   - **Thought**: This does not align with the user’s preferences.\n",
      "\n",
      "10. **Harriet Beamer Takes the Bus (Harriet Beamer Series)**\n",
      "    - **Categories**: Christian Books & Bibles, Literature & Fiction\n",
      "    - **Thought**: This book is a series and may appeal to the user if it has educational or cultural elements, but it is still primarily a work of fiction.\n",
      "\n",
      "### Step 4: Observation\n",
      "None of the candidate products align closely with the user's preferences for children's books, educational content, or cookbooks. \n",
      "\n",
      "### Step 5: Thought\n",
      "Given the lack of alignment with the user's preferences in the candidate products, it seems that none of these items would be suitable recommendations.\n",
      "\n",
      "### Answer\n",
      "Based on the analysis, the ranking of the candidate products in relation to the user's preferences is: **[ ]** (no suitable recommendations).\"\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Book heavy ReAct\n",
      "====================================================================================================\n",
      "'[]'\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "'[]'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gpt-4o-mini Amazon_Book heavy Generate-Item\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# why inference failed in each thought process\n",
    "model_name = \"gpt-4o-mini\"\n",
    "dict_error = ddict_error[model_name]\n",
    "\n",
    "for data_name, d1 in dict_error.items():\n",
    "    for exp_name, d2 in d1.items():\n",
    "        for type_prompt, d3 in d2.items():\n",
    "            idx = 0\n",
    "            for k,v in d3[\"text\"].items():\n",
    "                t = v[\"answers\"][-1]\n",
    "                try:\n",
    "                    l = [int(a) for a in t.split(\"[\")[1].split(\"]\")[0].replace(\"\\\\\", \"\").split(\",\")]\n",
    "                except:\n",
    "                    print(v[\"thought\"])\n",
    "                    print(\"- \" * 50)\n",
    "                    print(t)\n",
    "                    print(\"--\" * 50)\n",
    "                    idx += 1\n",
    "\n",
    "            if idx > 0:\n",
    "                print(model_name, data_name, exp_name, type_prompt)\n",
    "                print(\"==\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9fc2f-763c-4f2f-9a55-1a53f72c721d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e7772-6c2d-476e-87b3-9c42d49e3102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098305be-6631-4346-b32e-500abe7e61da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3afa7-a5b7-47fa-890b-f244acdf0cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
