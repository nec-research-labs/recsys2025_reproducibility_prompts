{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4721f7d-9c44-48ca-893f-dbe90fa6ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "HERE = %pwd\n",
    "sys.path.append(os.path.dirname(HERE))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e86792-aff5-422f-8957-6d730ed5cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "\n",
    "utils.set_seed()\n",
    "\n",
    "# LLM names\n",
    "d_model = {\n",
    "    \"gpt-4.1-mini-2025-04-14\" : \"gpt-4.1-mini\",\n",
    "    \"llama3-3-70b-instruct-v1\" : \"llama3.3-70b\", \n",
    "    \"gpt-4o-mini-2024-07-18\" : \"gpt-4o-mini\", \n",
    "    \"phi4\" : \"phi4\",\n",
    "    \"nova-lite-v1\" : \"amazon-nova-lite\"\n",
    "}\n",
    "model_names = list(d_model.keys())\n",
    "model_name = model_names[0]\n",
    "llm = utils.load_llm(model_name)\n",
    "\n",
    "data_names = [\"Yelp\", \"MIND\", \"Food\"] + [f\"Amazon_{a}\" for a in [\"Movie\", \"Music\", \"Grocery\", \"Clothes\", \"Book\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca665ea-ff9c-44e2-a30e-2f9a044fb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_name in data_names:\n",
    "    print(utils.now(), data_name)\n",
    "    \n",
    "    # preprocessed directory\n",
    "    version_prep = \"20250403_prep\"\n",
    "    dir_prep_data = f\"../data/preprocessed_data/{version_prep}/{data_name}\"\n",
    "    llm.path_log = f\"{dir_prep_data}/llm_log_item_summary_{model_name}.txt\"\n",
    "\n",
    "    if \"Amazon\" in data_name:\n",
    "        columns_item = [\"title\", \"categories\", \"description\"]\n",
    "        domain = data_name.split(\"Amazon_\")[1].lower()\n",
    "    elif \"Yelp\" in data_name:\n",
    "        columns_item = ['name', 'attributes', 'categories'] \n",
    "        domain = \"business\"\n",
    "    elif \"MIND\" in data_name:\n",
    "        columns_item = ['title', 'category', 'subcategory', 'abstract']  \n",
    "        domain = \"news\"\n",
    "    elif \"Food\" in data_name:\n",
    "        columns_item = [\"name\", \"tags\", \"description\", \"ingredients\"]\n",
    "        domain = \"recipe\"\n",
    "\n",
    "    df_items = pd.read_csv(f\"{dir_prep_data}/items_slim.csv\", index_col=0).fillna(\"\")\n",
    "    df_items = df_items[columns_item]\n",
    "\n",
    "    # generate summarized item text\n",
    "    try:\n",
    "        df_ = pd.read_csv(f\"{dir_prep_data}/items_slim_with_summary_{model_name}.csv\", index_col=0)\n",
    "    except:\n",
    "        d_s = dict()\n",
    "        for id_item, d_ in tqdm(df_items.T.to_dict().items()):\n",
    "\n",
    "            # summarizing prompt\n",
    "            prompt = f\"\"\"We have the following item details in the {domain} domain:\n",
    "# Item Information\n",
    "{d_}\n",
    "\n",
    "Please summarize this item information, ensuring to include key features and attributes to enhance clarity and understanding wihtin 10-200 words\"\"\"\n",
    "\n",
    "            # retry function\n",
    "            i = 0\n",
    "            n = 5\n",
    "            while i < n:\n",
    "                try:\n",
    "                    output, log = llm(prompt, log=True)\n",
    "                    assert log[\"output token\"] > 10\n",
    "                    assert log[\"output token\"] < 500\n",
    "                    i = n + 1\n",
    "                except:\n",
    "                    i += 1\n",
    "\n",
    "            # if failed, we use the summarized text as the top 1000 characters of item description.\n",
    "            if i == n:\n",
    "                print(id_item)\n",
    "                print(d_)\n",
    "                print(log)\n",
    "                print(\"==\")\n",
    "                output = str(d_)[:1000]\n",
    "        \n",
    "            d_s[id_item] = output\n",
    "    \n",
    "        df_ = df_items.copy()\n",
    "        df_[\"summary\"] = pd.Series(d_s).copy()\n",
    "        df_.to_csv(f\"{dir_prep_data}/items_slim_with_summary_{model_name}.csv\")\n",
    "    \n",
    "    print(llm.compute_log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544b4d5-348b-4140-865f-646f57d1e5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62ed79-6166-4500-9e3d-6501a9b3085e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca983e-06ed-4d72-8e6b-78b8436490d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
